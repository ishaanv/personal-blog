<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog on Ishaan Varshney</title>
    <link>https://ishaanv.github.io/blog/index.xml</link>
    <description>Recent content in Blog on Ishaan Varshney</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Tue, 17 Jan 2017 10:44:09 +1100</lastBuildDate>
    <atom:link href="https://ishaanv.github.io/blog/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Confidence Intervals vs Prediction Intervals</title>
      <link>https://ishaanv.github.io/blog/confidence-intervals-vs-prediction-intervals/</link>
      <pubDate>Tue, 17 Jan 2017 10:44:09 +1100</pubDate>
      
      <guid>https://ishaanv.github.io/blog/confidence-intervals-vs-prediction-intervals/</guid>
      <description>

&lt;!-- ![formaulas](/blog/stats/formulas.png &#34;tl;dr :P&#34;) --&gt;

&lt;!-- TODO increase size in mathjax and save mathjax setting --&gt;

&lt;!-- &lt;iframe width=&#34;900&#34; height=&#34;800&#34; frameborder=&#34;0&#34; scrolling=&#34;no&#34; src=&#34;https://plot.ly/~ishaanvar/2.embed&#34;&gt;&lt;/iframe&gt; --&gt;

&lt;!-- &lt;iframe width=&#34;900&#34; height=&#34;800&#34; frameborder=&#34;0&#34; scrolling=&#34;no&#34; src=&#34;https://ishaanv.github.io/blog/stats/simple-3d-scatter1.html&#34;&gt;&lt;/iframe&gt; --&gt;

&lt;h2 id=&#34;context&#34;&gt;Context&lt;/h2&gt;

&lt;p&gt;Statistics is useful because it helps us predict phenonemen. However, whenever we enter the field of predictions we also need to provide a level of uncertainty (or confidence) associated with that estimate.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s explore the idea of uncertainty with an example.&lt;/p&gt;

&lt;h3 id=&#34;tv-advertising-sales&#34;&gt;TV advertising -&amp;gt; Sales&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;This example is from book &lt;a href=&#34;http://www-bcf.usc.edu/~gareth/ISL/&#34;&gt;Introduction to Statistical Learning&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;data&#34;&gt;Data&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;advertising_data.head()[[&#39;TV&#39;, &#39;Sales&#39;]]
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34; style=&#34;text-align: center;&#34;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;TV&lt;/th&gt;
      &lt;th&gt;Sales&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;230.1&lt;/td&gt;
      &lt;td&gt;22.1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;44.5&lt;/td&gt;
      &lt;td&gt;10.4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;17.2&lt;/td&gt;
      &lt;td&gt;9.3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;151.5&lt;/td&gt;
      &lt;td&gt;18.5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;180.8&lt;/td&gt;
      &lt;td&gt;12.9&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h3 id=&#34;regression&#34;&gt;Regression&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s perform simple linear regresssion with TV advertising being the independant variable&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import statsmodels.formula.api as sm
res = sm.ols(&amp;quot;Sales ~ TV&amp;quot;, advertising_data).fit()
plt.plot(advertising_data[&amp;quot;TV&amp;quot;], advertising_data[&#39;Sales&#39;], &#39;ro&#39;)
plt.plot(advertising_data[&amp;quot;TV&amp;quot;], res.fittedvalues, &#39;b&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ishaanv.github.io/blog/stats/regression_output_6_1.png&#34; alt=&#34;regression&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now let&amp;rsquo;s plot the confidence and prediction intervals on the historical data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from statsmodels.stats.outliers_influence import summary_table
st, data, ss2 = summary_table(res, alpha=0.05)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I recommend exploring the output of &lt;code&gt;summary_table&lt;/code&gt; as it contains information relating to confidence and prediction intervals. Also the docs for statsmodels are not too helpful in this area.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ci_low = data[:,4]
ci_hi = data[:,5]
pi_low = data[:,6]
pi_hi = data[:,7]


plt.plot(advertising_data[&amp;quot;TV&amp;quot;], advertising_data[&#39;Sales&#39;], &#39;ro&#39;)
plt.plot(advertising_data[&amp;quot;TV&amp;quot;], res.fittedvalues, &#39;b&#39;)
plt.plot(advertising_data[&amp;quot;TV&amp;quot;], ci_low, &#39;g--&#39;)
plt.plot(advertising_data[&amp;quot;TV&amp;quot;], ci_hi, &#39;g--&#39;)
plt.plot(advertising_data[&amp;quot;TV&amp;quot;], pi_low, &#39;c--&#39;)
plt.plot(advertising_data[&amp;quot;TV&amp;quot;], pi_hi, &#39;c--&#39;)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://ishaanv.github.io/blog/stats/output_6_1.png&#34; alt=&#34;regression&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;predictions&#34;&gt;Predictions&lt;/h3&gt;

&lt;p&gt;We can either:&lt;/p&gt;

&lt;p&gt;1) predict the &lt;em&gt;average sales&lt;/em&gt; of branches that spent 100,000 units on TV advertising&lt;/p&gt;

&lt;p&gt;2) predict the sales of &lt;em&gt;one branch&lt;/em&gt; that spent 100,000 units on TV adversiting&lt;/p&gt;

&lt;p&gt;Depending which of the above we choose to predict, we will have different error bounds as there are differing levels of uncertainty associated with each prediction. However, the bounds for the both cases will centre around the same point. In other words, they will both predict the same value&lt;/p&gt;

&lt;p&gt;The bounds associated with (1) average prediction is called the confidence interval. While the bounds around (2) a single point is called the prediction interval.&lt;/p&gt;

&lt;p&gt;The bounds for a single point will be greater than the average of those points. There is greater uncertainty associated with the a single prediction because we have to account for irreducible errors. When we take the average of the points we assume that the irrecible errors from all the points will cancel each other out.&lt;/p&gt;

&lt;p&gt;At some point, I&amp;rsquo;ll do a post about irreducible errors in a linear regression to explore this idea further.&lt;/p&gt;

&lt;h1 id=&#34;calculating-confidence-intervals-for-an-exogenous-point&#34;&gt;Calculating confidence intervals for an exogenous point.&lt;/h1&gt;

&lt;p&gt;Using our simple linear regression model, let&amp;rsquo;s predict the &lt;code&gt;Sales&lt;/code&gt; when we spend 100 units on &lt;code&gt;TV&lt;/code&gt; advertising and the associated CI and PI values.&lt;/p&gt;

&lt;h3 id=&#34;by-hand&#34;&gt;By hand&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;$$
CI: \hat{y}\space \pm \space  t_{n-2}^\star s\sqrt{\frac{1}{n} + \frac{(x^* - \bar{x})^2}{((n-1)s_x^2)}} 
\\
\\
PI: \hat{y}\space \pm \space  t_{n-2}^\star s\sqrt{1 + \frac{1}{n} + \frac{(x^* - \bar{x})^2}{((n-1)s_x^2)}}
$$&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;where s is the residual standard error&lt;/p&gt;

&lt;p&gt;Calulating the &lt;strong&gt;confidence intervals&lt;/strong&gt; from scratch we get:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from scipy import stats

x = 1/len(advertising_data) + (pow(100-tv_bar,2)/((len(advertising_data)-1)*pow(tv_s,2)))
conf_low = pred - stats.t.ppf(1-0.025, 198) * se*pow(x, 0.5)
conf_hi = pred + stats.t.ppf(1-0.025, 198) * se*pow(x, 0.5)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Output&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt; print(conf_low, conf_hi)
&amp;gt;&amp;gt; [ 11.26583257] [ 12.30668261]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Calculating the &lt;strong&gt;prediction intervals&lt;/strong&gt; from scratch, we get:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
rss = sum([pow(advertising_data[&amp;quot;TV&amp;quot;], 2) for x in res.resid])
rse = pow(rss/(len(advertising_data[&#39;Sales&#39;])-2), 0.5)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;RSE can be thought of as the standard deviation of the residuals.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from scipy import stats
# using the above formula
x = 1 + 1/len(advertising_data) + 
    (pow(100-tv_bar,2)/((len(advertising_data)-1)*pow(tv_s,2)))
pred_low = pred - stats.t.ppf(1-0.025, 198) * se*pow(x, 0.5)
pred_hi = pred + stats.t.ppf(1-0.025, 198) * se*pow(x, 0.5)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Output&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;gt;&amp;gt; print(conf_low, conf_hi)
&amp;gt;&amp;gt; [ 5.31828015] [ 18.25423503]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Alternatively one can find the prediction interval bounds by:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from statsmodels.sandbox.regression.predstd import wls_prediction_std

pred = res.predict(exog={&amp;quot;TV&amp;quot;:100})
_ pred_low, pred_high = wls_prediction_std(res, exog=[1,100], weights=1)

# However we get slightly different results. Not 100% that it&#39;s just rounding error]

Output:
[ 5.33925132] [ 18.23326387]
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;takeaways&#34;&gt;Takeaways&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Confidence intervals can be thought of as the error bounds associated with average of several points at that value.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Prediction intervals are the error bounds for the single point.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Confidence intervals are narrower than prediciton intervals because the average of the points cancels out the irreducible error.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Python&amp;rsquo;s &lt;code&gt;statsmodels&lt;/code&gt; library&amp;rsquo;s documentation and interface is not as clean as the R language&amp;rsquo;s. We should work towards bettering it.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>